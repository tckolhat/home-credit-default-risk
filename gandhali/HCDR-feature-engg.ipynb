{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee00ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def load_data(in_path, name):\n",
    "    df = pd.read_csv(in_path)\n",
    "    return df\n",
    "\n",
    "def load_datasets(DATA_DIR, ds_names):\n",
    "    datasets = {}\n",
    "    for ds_name in ds_names:\n",
    "        datasets[ds_name] = load_data(os.path.join(DATA_DIR, f'{ds_name}.csv'), ds_name)\n",
    "    return datasets\n",
    "    \n",
    "def pct(x):\n",
    "    return round(100*x,3)\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, precision_recall_curve, f1_score\n",
    "\n",
    "def show_scores(y, y_pred, percentages=False):\n",
    "    conf_mx = confusion_matrix(y, y_pred)\n",
    "    if percentages:\n",
    "        conf_mx = 100*conf_mx/y.shape[0]\n",
    "    print('scores\\n')\n",
    "    print('precision', precision_score(y, y_pred))\n",
    "    print('recall   ', recall_score(y, y_pred))\n",
    "    print('f1       ', f1_score(y, y_pred))\n",
    "    print('accuracy ', np.sum(y == y_pred)/y.shape[0])\n",
    "\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(conf_mx, annot=True, fmt='3.1f')\n",
    "    \n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    \n",
    "from IPython.display import display, HTML, Javascript\n",
    "\n",
    "js_getResults = \"\"\"<script>\n",
    "alert(\"Hello! I am an alert box!\");\n",
    "</script>\"\"\"\n",
    "\n",
    "def alert():\n",
    "    display(HTML(js_getResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "250c931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e64ebe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/gandhalimarunmale/Documents/home-credit-default-risk/Data/home-credit-default-risk\"\n",
    "ds_names = (\"application_train\", \"previous_application\")\n",
    "datasets = load_datasets(DATA_DIR, ds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "72b9aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days Tranformation \n",
    "def transform_days(X):\n",
    "    mask = X > 0\n",
    "    X[mask] = np.NaN\n",
    "    # return np.log1p(-1*X)\n",
    "    return -X\n",
    "\n",
    "def preprocessing_transformations(df, inplace=False, impute_zero =()):\n",
    "    # pure state-less transformations \n",
    "    if inplace:\n",
    "        df_new = df\n",
    "    else:\n",
    "        df_new = df.copy()\n",
    "    \n",
    "    right_skewed = ['AMT_ANNUITY']\n",
    "    left_skewed = []\n",
    "    days = ['DAYS_EMPLOYED']\n",
    "    \n",
    "    transform_left_skewed = lambda X: np.log(1+np.max(X)-X)\n",
    "    \n",
    "    df_new[right_skewed] = np.log1p(df[right_skewed])\n",
    "    df_new[left_skewed] = transform_left_skewed(df[left_skewed])\n",
    "    df_new[days] = transform_days(df[days])\n",
    "    \n",
    "    # others\n",
    "    df_new[impute_zero] = SimpleImputer(strategy='constant', fill_value=0).fit_transform(df_new[impute_zero])\n",
    "    df_new['NAME_FAMILY_STATUS'].replace('Unknown', np.nan, inplace=True)\n",
    "    df_new['ORGANIZATION_TYPE'].replace('XNA', np.nan, inplace=True)\n",
    "    df_new['CODE_GENDER'].replace('XNA', np.nan, inplace=True)\n",
    "    return df_new\n",
    "    \n",
    "def add_new_features(df, inplace=False):\n",
    "    if inplace:\n",
    "        X = df\n",
    "    else:\n",
    "        X = df.copy()\n",
    "    X['annuity_income_percentage'] = X['AMT_ANNUITY'] / X['AMT_INCOME_TOTAL']\n",
    "    X['car_to_birth_ratio'] = X['OWN_CAR_AGE'] / X['DAYS_BIRTH']\n",
    "    X['car_to_employ_ratio'] = X['OWN_CAR_AGE'] / (1+X['DAYS_EMPLOYED'])\n",
    "    X['children_ratio'] = X['CNT_CHILDREN'] / X['CNT_FAM_MEMBERS']\n",
    "    X['credit_to_annuity_ratio'] = X['AMT_CREDIT'] / X['AMT_ANNUITY']\n",
    "    X['credit_to_goods_ratio'] = X['AMT_CREDIT'] / X['AMT_GOODS_PRICE']\n",
    "    X['credit_to_income_ratio'] = X['AMT_CREDIT'] / X['AMT_INCOME_TOTAL']\n",
    "    X['days_employed_percentage'] = X['DAYS_EMPLOYED'] / X['DAYS_BIRTH']\n",
    "    X['income_credit_percentage'] = X['AMT_INCOME_TOTAL'] / X['AMT_CREDIT']\n",
    "    X['income_per_child'] = X['AMT_INCOME_TOTAL'] / (1 + X['CNT_CHILDREN'])\n",
    "    X['income_per_person'] = X['AMT_INCOME_TOTAL'] / X['CNT_FAM_MEMBERS']\n",
    "    X['payment_rate'] = X['AMT_ANNUITY'] / X['AMT_CREDIT']\n",
    "    X['phone_to_birth_ratio'] = X['DAYS_LAST_PHONE_CHANGE'] / X['DAYS_BIRTH']\n",
    "    X['phone_to_employ_ratio'] = X['DAYS_LAST_PHONE_CHANGE'] / (1+X['DAYS_EMPLOYED'])\n",
    "    X['external_source_mean'] = X[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    X['cnt_non_child'] = X['CNT_FAM_MEMBERS'] - X['CNT_CHILDREN']\n",
    "    X['child_to_non_child_ratio'] = X['CNT_CHILDREN'] / X['cnt_non_child']\n",
    "    X['income_per_non_child'] = X['AMT_INCOME_TOTAL'] / X['cnt_non_child']\n",
    "    X['credit_per_person'] = X['AMT_CREDIT'] / X['CNT_FAM_MEMBERS']\n",
    "    X['credit_per_child'] = X['AMT_CREDIT'] / (1 + X['CNT_CHILDREN'])\n",
    "    X['credit_per_non_child'] = X['AMT_CREDIT'] / X['cnt_non_child']\n",
    "    \n",
    "    return X\n",
    "\n",
    "def prevAppsFeaturesAggregater(df, inplace=False):\n",
    "    # pure state-less transformations \n",
    "    if inplace:\n",
    "        df_new = df\n",
    "    else:\n",
    "        df_new = df.copy()\n",
    "        \n",
    "    # Sorted df by decsion day\n",
    "    prev_applications_sorted = df_new.sort_values(['SK_ID_CURR', 'DAYS_DECISION'])\n",
    "        \n",
    "    # Tranform days\n",
    "    days = ['DAYS_DECISION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION']\n",
    "    df_new[days] = transform_days(df[days])\n",
    "        \n",
    "    aggr_df = pd.DataFrame({'SK_ID_CURR': df_new['SK_ID_CURR'].unique()})\n",
    "    \n",
    "    # Compute min, max, min values\n",
    "    agg_ops = agg_ops = [\"min\", \"max\", \"mean\", \"sum\"]\n",
    "    features = ['AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE', 'CNT_PAYMENT', 'HOUR_APPR_PROCESS_START', 'RATE_DOWN_PAYMENT', 'DAYS_DECISION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION'] \n",
    "    X = df_new.groupby([\"SK_ID_CURR\"], as_index=False).agg({ft:agg_ops for ft in features})\n",
    "    X.columns = X.columns.map(lambda col: '_'.join([x for x in col if x != '']))\n",
    "    aggr_df = aggr_df.merge(X, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    #Previous Application Count\n",
    "    prev_appl_count = df_new.groupby(by=['SK_ID_CURR'])['SK_ID_PREV'].nunique().reset_index()\n",
    "    prev_appl_count.rename(index=str, columns={'SK_ID_PREV': 'previous_applications_count'}, inplace=True)\n",
    "    aggr_df = aggr_df.merge(prev_appl_count, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    #Previous applications approved count\n",
    "    df_new['prev_applications_approved'] = (df_new['NAME_CONTRACT_STATUS'] == 'Approved').astype('int')\n",
    "    approved_count = df_new.groupby(by=['SK_ID_CURR'])['prev_applications_approved'].sum().reset_index()\n",
    "    aggr_df = aggr_df.merge(approved_count, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    #Previous applications refused count\n",
    "    df_new['prev_applications_refused'] = (df_new['NAME_CONTRACT_STATUS'] == 'Refused').astype('int')\n",
    "    refused_count = df_new.groupby(by=['SK_ID_CURR'])['prev_applications_refused'].sum().reset_index()\n",
    "    aggr_df = aggr_df.merge(refused_count, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    #previous application invalid\n",
    "    df_new['prev_applications_invalid'] = (df_new['NAME_CONTRACT_STATUS'] == 'Canceled').astype('int') + (df_new['NAME_CONTRACT_STATUS'] == 'Unused offer').astype('int')\n",
    "    invalid_count = df_new.groupby(by=['SK_ID_CURR'])['prev_applications_invalid'].sum().reset_index()\n",
    "    aggr_df = aggr_df.merge(invalid_count, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    #Last application status(approved or rejected?)\n",
    "    prev_applications_sorted['prevAppl_last_approved'] = (prev_applications_sorted['NAME_CONTRACT_STATUS'] == 'Approved').astype('int')\n",
    "    last_approved = prev_applications_sorted.groupby(by=['SK_ID_CURR'])['prevAppl_last_approved'].last().reset_index()\n",
    "    aggr_df = aggr_df.merge(last_approved, how='left', on=['SK_ID_CURR'])\n",
    "    \n",
    "    return aggr_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e0b33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prep_pipeline(num_selected=None, cat_selected=None):\n",
    "    num_pipeline = Pipeline([\n",
    "        ('new_features', FunctionTransformer(add_new_features)),\n",
    "        ('selector', DataFrameSelector(num_selected)),\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_selected)),\n",
    "        #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    data_prep_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])\n",
    "    return data_prep_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7e110b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_train = datasets['application_train']\n",
    "prevData_aggr = prevAppsFeaturesAggregater(datasets['previous_application'])\n",
    "data_aggr = appl_train.merge(prevData_aggr, how='left', on=['SK_ID_CURR'])\n",
    "impute_zero = ['OWN_CAR_AGE', 'previous_applications_count', 'prev_applications_approved', \n",
    "               'prev_applications_refused', 'prev_applications_invalid', 'prevAppl_last_approved']\n",
    "processed_data = preprocessing_transformations(data_aggr, impute_zero=impute_zero)\n",
    "\n",
    "y = processed_data['TARGET']\n",
    "X = processed_data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02e7a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app_num_attribs = ['AMT_INCOME_TOTAL', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_CREDIT', 'REGION_POPULATION_RELATIVE',\n",
    "                   'DAYS_EMPLOYED', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_ID_PUBLISH',\n",
    "                   'DAYS_REGISTRATION', 'DAYS_LAST_PHONE_CHANGE', 'OWN_CAR_AGE', 'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "                   'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "                   'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                   'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "                   'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY',\n",
    "                   'HOUR_APPR_PROCESS_START']\n",
    "new_app_attribs = ['annuity_income_percentage', 'car_to_birth_ratio', 'car_to_employ_ratio', 'children_ratio',\n",
    "                    'credit_to_annuity_ratio', 'credit_to_goods_ratio', 'credit_to_income_ratio', 'days_employed_percentage',\n",
    "                    'income_credit_percentage', 'income_per_child', 'income_per_person', 'payment_rate', 'phone_to_birth_ratio',\n",
    "                    'phone_to_employ_ratio', 'external_source_mean', 'cnt_non_child', 'child_to_non_child_ratio',\n",
    "                    'income_per_non_child', 'credit_per_person', 'credit_per_child', 'credit_per_non_child']\n",
    "prev_aggr_attribs = prevData_aggr.columns.to_list()\n",
    "\n",
    "app_cat_attribs = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE',\n",
    "                   'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE',\n",
    "                   'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE',\n",
    "                   'FLAG_EMAIL', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION',\n",
    "                   'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2',\n",
    "                   'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n",
    "                   'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "                   'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n",
    "                   'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']\n",
    "\n",
    "num_attribs = app_num_attribs + new_app_attribs + prev_aggr_attribs\n",
    "\n",
    "cat_attribs = app_cat_attribs\n",
    "\n",
    "data_prep_pipeline = make_prep_pipeline(num_attribs, cat_attribs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9351e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.9 s, sys: 990 ms, total: 1min\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(42)\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", data_prep_pipeline),\n",
    "#         (\"feature_selector\", SelectFromModel(RandomForestClassifier(\n",
    "#         class_weight='balanced', \n",
    "#         random_state=0))),\n",
    "#         (\"linear\", LogisticRegression(class_weight='balanced'))\n",
    "        (\"random_forest\", RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\", n_jobs=4))\n",
    "    ])\n",
    "model = full_pipeline_with_predictor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "80ea87eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 112, 205)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline = data_prep_pipeline.transformer_list[1][1]\n",
    "cat_features = [f'{base}_{c}'for base, ohe_c in zip(\n",
    "    cat_attribs, cat_pipeline.named_steps['ohe'].categories_) for c in ohe_c]\n",
    "features = num_attribs + cat_features\n",
    "len(features), len(num_attribs), len(cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "72b0c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector_model = full_pipeline_with_predictor.named_steps['L1_selector']\n",
    "# selected_features = list(np.array(features)[selector_model.get_support()])\n",
    "# len(num_attribs + cat_attribs), len(features), len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed1caf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_attribs = set([f if f in num_attribs else '_'.join(f.split('_')[:-1]) for f in selected_features])\n",
    "# unused_attribs = set(num_attribs+cat_attribs) - selected_attribs\n",
    "# unused_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b24d9198",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_train_pred = y_train_pred_proba > 0.5\n",
    "y_test_pred = y_test_pred_proba > 0.5\n",
    "# scores = cross_val_score(model, X_train, y_train, cv=4, scoring='roc_auc', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e8286c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>4-fold Valid AUC</th>\n",
       "      <th>4-fold Valid AUC std</th>\n",
       "      <th>Test  AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>RandomForest_108_features</td>\n",
       "      <td>0.7465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>RandomForest_104_features</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RandomForest_103_features</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      exp_name  Train AUC  4-fold Valid AUC  \\\n",
       "108  RandomForest_108_features     0.7465               0.0   \n",
       "104  RandomForest_104_features     0.7610               0.0   \n",
       "103  RandomForest_103_features     0.8279               0.0   \n",
       "\n",
       "     4-fold Valid AUC std  Test  AUC  \n",
       "108                   0.0     0.7438  \n",
       "104                   0.0     0.7623  \n",
       "103                   0.0     0.7532  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train AUC\", \n",
    "                                   \"4-fold Valid AUC\",\n",
    "                                   \"4-fold Valid AUC std\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"RandomForest_{len(selected_features)}_features\"\n",
    "expLog.loc[len(selected_features)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [roc_auc_score(y_train, y_train_pred_proba), 0, 0,\n",
    "#                 scores.mean(),\n",
    "#                 scores.std(),\n",
    "                roc_auc_score(y_test, y_test_pred_proba)],\n",
    "    4)) \n",
    "expLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d6a937a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_forest__bootstrap': [True, False], 'random_forest__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'random_forest__max_features': ['auto', 'sqrt'], 'random_forest__min_samples_leaf': [1, 2, 4], 'random_forest__min_samples_split': [2, 5, 10], 'random_forest__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "paramters = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "distributions = {\"random_forest__\" + k:v for (k,v) in paramters.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c1b4f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV 2/3] END random_forest__max_depth=7;, score=(train=0.776, test=0.744) total time= 1.0min\n",
      "[CV 3/3] END random_forest__max_depth=10;, score=(train=0.850, test=0.746) total time= 1.5min\n",
      "[CV 1/3] END random_forest__max_depth=7;, score=(train=0.778, test=0.746) total time= 1.1min\n",
      "[CV 1/3] END random_forest__max_depth=13;, score=(train=0.938, test=0.742) total time= 1.7min\n",
      "[CV 1/3] END random_forest__max_depth=10;, score=(train=0.850, test=0.745) total time= 1.4min\n",
      "[CV 2/3] END random_forest__max_depth=13;, score=(train=0.934, test=0.743) total time= 1.6min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(full_pipeline_with_predictor, param_distributions=distributions, \n",
    "                         scoring=\"roc_auc\", n_jobs=4, cv=3, verbose=3, random_state=42, return_train_score=True)\n",
    "_ = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "db4aa3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest__max_depth': 10}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c024054a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7459976997840134"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ba33c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([60.00341829, 83.40570664, 85.51867541]),\n",
       " 'std_fit_time': array([ 2.88882414,  4.77594272, 17.36083569]),\n",
       " 'mean_score_time': array([4.36803993, 4.06988796, 2.48051429]),\n",
       " 'std_score_time': array([0.36533548, 0.99385639, 0.29562373]),\n",
       " 'param_random_forest__max_depth': masked_array(data=[7, 10, 13],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'random_forest__max_depth': 7},\n",
       "  {'random_forest__max_depth': 10},\n",
       "  {'random_forest__max_depth': 13}],\n",
       " 'split0_test_score': array([0.74586851, 0.74544121, 0.74249155]),\n",
       " 'split1_test_score': array([0.74399393, 0.74665884, 0.74311097]),\n",
       " 'split2_test_score': array([0.7423203 , 0.74589305, 0.74302514]),\n",
       " 'mean_test_score': array([0.74406091, 0.7459977 , 0.74287589]),\n",
       " 'std_test_score': array([0.00144933, 0.00050257, 0.00027402]),\n",
       " 'rank_test_score': array([2, 1, 3], dtype=int32),\n",
       " 'split0_train_score': array([0.77820049, 0.8499154 , 0.9379599 ]),\n",
       " 'split1_train_score': array([0.77587391, 0.84515879, 0.93421009]),\n",
       " 'split2_train_score': array([0.77651282, 0.84960814, 0.93633293]),\n",
       " 'mean_train_score': array([0.77686241, 0.84822744, 0.93616764]),\n",
       " 'std_train_score': array([0.00098146, 0.00217349, 0.00153531])}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END random_forest__max_depth=7;, score=(train=0.777, test=0.742) total time= 1.1min\n",
      "[CV 2/3] END random_forest__max_depth=10;, score=(train=0.845, test=0.747) total time= 1.5min\n",
      "[CV 3/3] END random_forest__max_depth=13;, score=(train=0.936, test=0.743) total time= 1.1min\n"
     ]
    }
   ],
   "source": [
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2489739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'mean_fit_time': array([60.00341829, 83.40570664, 85.51867541]),\n",
      "    'mean_score_time': array([4.36803993, 4.06988796, 2.48051429]),\n",
      "    'mean_test_score': array([0.74406091, 0.7459977 , 0.74287589]),\n",
      "    'mean_train_score': array([0.77686241, 0.84822744, 0.93616764]),\n",
      "    'param_random_forest__max_depth': masked_array(data=[7, 10, 13],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      "    'params': [   {'random_forest__max_depth': 7},\n",
      "                  {'random_forest__max_depth': 10},\n",
      "                  {'random_forest__max_depth': 13}],\n",
      "    'rank_test_score': array([2, 1, 3], dtype=int32),\n",
      "    'split0_test_score': array([0.74586851, 0.74544121, 0.74249155]),\n",
      "    'split0_train_score': array([0.77820049, 0.8499154 , 0.9379599 ]),\n",
      "    'split1_test_score': array([0.74399393, 0.74665884, 0.74311097]),\n",
      "    'split1_train_score': array([0.77587391, 0.84515879, 0.93421009]),\n",
      "    'split2_test_score': array([0.7423203 , 0.74589305, 0.74302514]),\n",
      "    'split2_train_score': array([0.77651282, 0.84960814, 0.93633293]),\n",
      "    'std_fit_time': array([ 2.88882414,  4.77594272, 17.36083569]),\n",
      "    'std_score_time': array([0.36533548, 0.99385639, 0.29562373]),\n",
      "    'std_test_score': array([0.00144933, 0.00050257, 0.00027402]),\n",
      "    'std_train_score': array([0.00098146, 0.00217349, 0.00153531])}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "pp.pprint(clf.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
